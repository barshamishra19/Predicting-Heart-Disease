{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f37a048",
   "metadata": {
    "papermill": {
     "duration": 0.005117,
     "end_time": "2026-02-07T15:31:10.968182",
     "exception": false,
     "start_time": "2026-02-07T15:31:10.963065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ü´Ä Heart Disease Prediction - ULTRA OPTIMIZED VERSION\n",
    "\n",
    "**Target Score: 0.955+ ROC-AUC (Beat 0.95393)**\n",
    "\n",
    "### Ultra Improvements:\n",
    "- ‚úÖ **Seed Averaging** (5 seeds for variance reduction)\n",
    "- ‚úÖ **7-Model Ensemble** (Added GaussianNB, RandomForest, MLP)\n",
    "- ‚úÖ **Pseudo-Labeling** (High-confidence test samples)\n",
    "- ‚úÖ **QuantileTransformer** (Better normalization)\n",
    "- ‚úÖ **Blend-of-Blends** (Combine all ensemble methods)\n",
    "- ‚úÖ **Stronger Regularization** (Combat overfitting)\n",
    "- ‚úÖ **Optuna Ready** (100 trials)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66299332",
   "metadata": {
    "papermill": {
     "duration": 0.003997,
     "end_time": "2026-02-07T15:31:10.976364",
     "exception": false,
     "start_time": "2026-02-07T15:31:10.972367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78947e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:10.985517Z",
     "iopub.status.busy": "2026-02-07T15:31:10.985226Z",
     "iopub.status.idle": "2026-02-07T15:31:18.766840Z",
     "shell.execute_reply": "2026-02-07T15:31:18.766094Z"
    },
    "papermill": {
     "duration": 7.788116,
     "end_time": "2026-02-07T15:31:18.768436",
     "exception": false,
     "start_time": "2026-02-07T15:31:10.980320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "Using 3 seeds for averaging: [42, 123, 456]\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# ML Tools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Gradient Boosting Models\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Optimization\n",
    "import optuna\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Configuration\n",
    "SEEDS = SEEDS = [42, 123, 456]  # Multiple seeds for averaging\n",
    "BASE_SEED = 42\n",
    "np.random.seed(BASE_SEED)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"Using {len(SEEDS)} seeds for averaging: {SEEDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e8baa3",
   "metadata": {
    "papermill": {
     "duration": 0.00415,
     "end_time": "2026-02-07T15:31:18.776964",
     "exception": false,
     "start_time": "2026-02-07T15:31:18.772814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7faec5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:18.786447Z",
     "iopub.status.busy": "2026-02-07T15:31:18.785903Z",
     "iopub.status.idle": "2026-02-07T15:31:19.757195Z",
     "shell.execute_reply": "2026-02-07T15:31:19.756350Z"
    },
    "papermill": {
     "duration": 0.977853,
     "end_time": "2026-02-07T15:31:19.758907",
     "exception": false,
     "start_time": "2026-02-07T15:31:18.781054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (630000, 15), Test: (270000, 14)\n",
      "Target distribution:\n",
      "Heart Disease\n",
      "Absence     0.55166\n",
      "Presence    0.44834\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target unique values: ['Presence' 'Absence']\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "# For Kaggle:\n",
    "DATA_DIR = '/kaggle/input/playground-series-s6e2'\n",
    "\n",
    "# For local (uncomment if testing locally):\n",
    "# DATA_DIR = r'c:\\Users\\barsha mishra\\Desktop\\myprojects\\kaggle\\Predicting Heart Disease'\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))\n",
    "\n",
    "# Constants\n",
    "TARGET = 'Heart Disease'\n",
    "ID_COL = 'id'\n",
    "\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")\n",
    "print(f\"Target distribution:\\n{train[TARGET].value_counts(normalize=True)}\")\n",
    "print(f\"\\nTarget unique values: {train[TARGET].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6aae6",
   "metadata": {
    "papermill": {
     "duration": 0.004356,
     "end_time": "2026-02-07T15:31:19.767757",
     "exception": false,
     "start_time": "2026-02-07T15:31:19.763401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Advanced Feature Engineering (Enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd3110b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:19.778278Z",
     "iopub.status.busy": "2026-02-07T15:31:19.778045Z",
     "iopub.status.idle": "2026-02-07T15:31:19.797026Z",
     "shell.execute_reply": "2026-02-07T15:31:19.796299Z"
    },
    "papermill": {
     "duration": 0.02563,
     "end_time": "2026-02-07T15:31:19.798419",
     "exception": false,
     "start_time": "2026-02-07T15:31:19.772789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering function defined!\n"
     ]
    }
   ],
   "source": [
    "def advanced_feature_engineering(df, is_train=True):\n",
    "    \"\"\"\n",
    "    ULTRA Feature Engineering - 35+ Features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    cols = df.columns.tolist()\n",
    "    new_features = []\n",
    "    \n",
    "    # ===== 1. Blood Pressure Features =====\n",
    "    if 'Systolic BP' in cols and 'Diastolic BP' in cols:\n",
    "        # Pulse Pressure (key indicator)\n",
    "        df['pulse_pressure'] = df['Systolic BP'] - df['Diastolic BP']\n",
    "        new_features.append('pulse_pressure')\n",
    "        \n",
    "        # Mean Arterial Pressure\n",
    "        df['map'] = (df['Systolic BP'] + 2 * df['Diastolic BP']) / 3\n",
    "        new_features.append('map')\n",
    "        \n",
    "        # BP Ratio\n",
    "        df['bp_ratio'] = df['Systolic BP'] / (df['Diastolic BP'] + 1)\n",
    "        new_features.append('bp_ratio')\n",
    "        \n",
    "        # Hypertension stages\n",
    "        df['is_hypertensive'] = ((df['Systolic BP'] > 140) | (df['Diastolic BP'] > 90)).astype(int)\n",
    "        df['hypertension_stage'] = 0\n",
    "        df.loc[(df['Systolic BP'] >= 120) & (df['Systolic BP'] < 130), 'hypertension_stage'] = 1\n",
    "        df.loc[(df['Systolic BP'] >= 130) | (df['Diastolic BP'] >= 80), 'hypertension_stage'] = 2\n",
    "        df.loc[(df['Systolic BP'] >= 140) | (df['Diastolic BP'] >= 90), 'hypertension_stage'] = 3\n",
    "        df.loc[(df['Systolic BP'] >= 180) | (df['Diastolic BP'] >= 120), 'hypertension_stage'] = 4\n",
    "        new_features.extend(['is_hypertensive', 'hypertension_stage'])\n",
    "        \n",
    "        # NEW: BP product\n",
    "        df['bp_product'] = df['Systolic BP'] * df['Diastolic BP'] / 1000\n",
    "        new_features.append('bp_product')\n",
    "    \n",
    "    # ===== 2. Age-Based Features =====\n",
    "    if 'Age' in cols:\n",
    "        # Age groups\n",
    "        df['age_decade'] = (df['Age'] // 10).astype(int)\n",
    "        new_features.append('age_decade')\n",
    "        \n",
    "        # Age risk factors\n",
    "        df['age_risk'] = (df['Age'] > 55).astype(int)\n",
    "        df['age_high_risk'] = (df['Age'] > 65).astype(int)\n",
    "        new_features.extend(['age_risk', 'age_high_risk'])\n",
    "        \n",
    "        # Age transformations\n",
    "        df['age_squared'] = df['Age'] ** 2\n",
    "        df['age_log'] = np.log1p(df['Age'])\n",
    "        new_features.extend(['age_squared', 'age_log'])\n",
    "    \n",
    "    # ===== 3. Cholesterol Features =====\n",
    "    if 'Cholesterol' in cols:\n",
    "        # Cholesterol risk categories\n",
    "        df['chol_risk'] = pd.cut(df['Cholesterol'], \n",
    "                                 bins=[0, 200, 239, 300, 1000], \n",
    "                                 labels=[0, 1, 2, 3]).astype(float).fillna(0)\n",
    "        new_features.append('chol_risk')\n",
    "        \n",
    "        # Cholesterol log (reduce skew)\n",
    "        df['chol_log'] = np.log1p(df['Cholesterol'])\n",
    "        new_features.append('chol_log')\n",
    "        \n",
    "        # NEW: Cholesterol squared\n",
    "        df['chol_squared'] = df['Cholesterol'] ** 2 / 10000\n",
    "        new_features.append('chol_squared')\n",
    "    \n",
    "    # ===== 4. Interaction Features =====\n",
    "    if 'Age' in cols and 'Cholesterol' in cols:\n",
    "        df['age_chol'] = df['Age'] * df['Cholesterol'] / 1000\n",
    "        df['chol_per_age'] = df['Cholesterol'] / (df['Age'] + 1)\n",
    "        new_features.extend(['age_chol', 'chol_per_age'])\n",
    "    \n",
    "    if 'Age' in cols and 'Systolic BP' in cols:\n",
    "        df['age_sbp'] = df['Age'] * df['Systolic BP'] / 1000\n",
    "        df['sbp_per_age'] = df['Systolic BP'] / (df['Age'] + 1)\n",
    "        new_features.extend(['age_sbp', 'sbp_per_age'])\n",
    "    \n",
    "    if 'Systolic BP' in cols and 'Cholesterol' in cols:\n",
    "        df['sbp_chol'] = df['Systolic BP'] * df['Cholesterol'] / 10000\n",
    "        new_features.append('sbp_chol')\n",
    "    \n",
    "    # ===== 5. Heart Rate Features =====\n",
    "    if 'Heart Rate' in cols:\n",
    "        df['hr_risk'] = ((df['Heart Rate'] < 60) | (df['Heart Rate'] > 100)).astype(int)\n",
    "        df['hr_log'] = np.log1p(df['Heart Rate'])\n",
    "        new_features.extend(['hr_risk', 'hr_log'])\n",
    "        \n",
    "        if 'Age' in cols:\n",
    "            df['max_hr'] = 220 - df['Age']\n",
    "            df['hr_reserve'] = df['max_hr'] - df['Heart Rate']\n",
    "            df['hr_percent_max'] = df['Heart Rate'] / df['max_hr']\n",
    "            new_features.extend(['max_hr', 'hr_reserve', 'hr_percent_max'])\n",
    "    \n",
    "    # ===== 6. BMI-related Features =====\n",
    "    if 'BMI' in cols:\n",
    "        df['bmi_category'] = pd.cut(df['BMI'], \n",
    "                                    bins=[0, 18.5, 25, 30, 100], \n",
    "                                    labels=[0, 1, 2, 3]).astype(float).fillna(1)\n",
    "        df['is_obese'] = (df['BMI'] >= 30).astype(int)\n",
    "        df['bmi_log'] = np.log1p(df['BMI'])\n",
    "        new_features.extend(['bmi_category', 'is_obese', 'bmi_log'])\n",
    "    \n",
    "    # ===== 7. Composite Risk Score (Enhanced) =====\n",
    "    risk_score = np.zeros(len(df))\n",
    "    if 'Age' in cols:\n",
    "        risk_score += (df['Age'] > 55).astype(int) * 2\n",
    "        risk_score += (df['Age'] > 65).astype(int) * 1\n",
    "    if 'is_hypertensive' in df.columns:\n",
    "        risk_score += df['is_hypertensive'] * 3\n",
    "    if 'Cholesterol' in cols:\n",
    "        risk_score += (df['Cholesterol'] > 240).astype(int) * 2\n",
    "    if 'Smoking' in cols:\n",
    "        risk_score += (df['Smoking'] == 1).astype(int) * 3\n",
    "    if 'Diabetes' in cols:\n",
    "        risk_score += (df['Diabetes'] == 1).astype(int) * 2\n",
    "    if 'Sex' in cols:\n",
    "        risk_score += (df['Sex'] == 'Male').astype(int) * 1\n",
    "    \n",
    "    df['composite_risk_score'] = risk_score\n",
    "    df['risk_category'] = pd.cut(risk_score, bins=[-1, 3, 6, 10, 20], labels=[0, 1, 2, 3]).astype(float).fillna(1)\n",
    "    new_features.extend(['composite_risk_score', 'risk_category'])\n",
    "    \n",
    "    # ===== 8. Statistical Features =====\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_cols = [c for c in num_cols if c not in [ID_COL, TARGET, 'composite_risk_score']]\n",
    "    \n",
    "    if len(num_cols) >= 3:\n",
    "        base_num_cols = num_cols[:6]  # Use first 6 numeric columns\n",
    "        df['row_mean'] = df[base_num_cols].mean(axis=1)\n",
    "        df['row_std'] = df[base_num_cols].std(axis=1)\n",
    "        df['row_max'] = df[base_num_cols].max(axis=1)\n",
    "        df['row_min'] = df[base_num_cols].min(axis=1)\n",
    "        df['row_range'] = df['row_max'] - df['row_min']\n",
    "        new_features.extend(['row_mean', 'row_std', 'row_max', 'row_min', 'row_range'])\n",
    "    \n",
    "    if is_train:\n",
    "        print(f\"‚úÖ Created {len(new_features)} new features\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Feature engineering function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb72f4d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:19.807852Z",
     "iopub.status.busy": "2026-02-07T15:31:19.807590Z",
     "iopub.status.idle": "2026-02-07T15:31:20.622541Z",
     "shell.execute_reply": "2026-02-07T15:31:20.621702Z"
    },
    "papermill": {
     "duration": 0.821417,
     "end_time": "2026-02-07T15:31:20.624109",
     "exception": false,
     "start_time": "2026-02-07T15:31:19.802692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Applying Advanced Feature Engineering ===\n",
      "‚úÖ Created 17 new features\n",
      "\n",
      "Train shape: (630000, 32)\n",
      "Test shape: (270000, 31)\n"
     ]
    }
   ],
   "source": [
    "# Apply Feature Engineering\n",
    "print(\"=== Applying Advanced Feature Engineering ===\")\n",
    "train_fe = advanced_feature_engineering(train, is_train=True)\n",
    "test_fe = advanced_feature_engineering(test, is_train=False)\n",
    "\n",
    "print(f\"\\nTrain shape: {train_fe.shape}\")\n",
    "print(f\"Test shape: {test_fe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6e0e6c",
   "metadata": {
    "papermill": {
     "duration": 0.004307,
     "end_time": "2026-02-07T15:31:20.633175",
     "exception": false,
     "start_time": "2026-02-07T15:31:20.628868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 4. Preprocessing with QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3eea3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:20.642969Z",
     "iopub.status.busy": "2026-02-07T15:31:20.642748Z",
     "iopub.status.idle": "2026-02-07T15:31:20.654564Z",
     "shell.execute_reply": "2026-02-07T15:31:20.653963Z"
    },
    "papermill": {
     "duration": 0.018596,
     "end_time": "2026-02-07T15:31:20.656008",
     "exception": false,
     "start_time": "2026-02-07T15:31:20.637412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing function defined!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(train_df, test_df, target_col, id_col, n_folds=10, use_quantile=True):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing with QuantileTransformer.\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    y = train_df[target_col].copy()\n",
    "    \n",
    "    # Encode target if categorical\n",
    "    if y.dtype == 'object' or str(y.dtype) == 'category':\n",
    "        target_le = LabelEncoder()\n",
    "        y = pd.Series(target_le.fit_transform(y), index=y.index)\n",
    "        print(f\"‚úÖ Target encoded: {list(target_le.classes_)} -> {list(range(len(target_le.classes_)))}\")\n",
    "    \n",
    "    X = train_df.drop([target_col, id_col], axis=1, errors='ignore')\n",
    "    X_test = test_df.drop([id_col], axis=1, errors='ignore')\n",
    "    \n",
    "    # Align columns\n",
    "    common_cols = X.columns.intersection(X_test.columns)\n",
    "    X = X[common_cols]\n",
    "    X_test = X_test[common_cols]\n",
    "    \n",
    "    print(f\"Features after alignment: {len(common_cols)}\")\n",
    "    \n",
    "    # Identify column types\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_cols = X.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"Numerical: {len(num_cols)}, Categorical: {len(cat_cols)}\")\n",
    "    \n",
    "    # Imputation\n",
    "    if num_cols:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
    "        X_test[num_cols] = num_imputer.transform(X_test[num_cols])\n",
    "    \n",
    "    # Categorical Encoding\n",
    "    if cat_cols:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])\n",
    "        X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])\n",
    "        \n",
    "        # Target encoding with cross-validation\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=BASE_SEED)\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            X[f'{col}_te'] = 0.0\n",
    "            X_test[f'{col}_te'] = 0.0\n",
    "            \n",
    "            global_mean = y.mean()\n",
    "            encoding_map = {}\n",
    "            \n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "                train_data = pd.DataFrame({'cat': X.iloc[train_idx][col], 'target': y.iloc[train_idx]})\n",
    "                encoding = train_data.groupby('cat')['target'].mean()\n",
    "                \n",
    "                X.iloc[val_idx, X.columns.get_loc(f'{col}_te')] = X.iloc[val_idx][col].map(encoding).fillna(global_mean)\n",
    "                \n",
    "                for cat_val, enc_val in encoding.items():\n",
    "                    if cat_val not in encoding_map:\n",
    "                        encoding_map[cat_val] = []\n",
    "                    encoding_map[cat_val].append(enc_val)\n",
    "            \n",
    "            final_encoding = {k: np.mean(v) for k, v in encoding_map.items()}\n",
    "            X_test[f'{col}_te'] = X_test[col].map(final_encoding).fillna(global_mean)\n",
    "            \n",
    "            # Label encode original categorical\n",
    "            le = LabelEncoder()\n",
    "            combined = pd.concat([X[col], X_test[col]]).astype(str)\n",
    "            le.fit(combined)\n",
    "            X[col] = le.transform(X[col].astype(str))\n",
    "            X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    \n",
    "    # Update num_cols\n",
    "    num_cols = X.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Scaling with QuantileTransformer (better than StandardScaler)\n",
    "    if num_cols:\n",
    "        if use_quantile:\n",
    "            scaler = QuantileTransformer(output_distribution='normal', n_quantiles=1000, random_state=BASE_SEED)\n",
    "            print(\"‚úÖ Using QuantileTransformer (output=normal)\")\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            print(\"Using StandardScaler\")\n",
    "        X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "        X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "    \n",
    "    return X, y, X_test\n",
    "\n",
    "print(\"Preprocessing function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5beddc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:20.665745Z",
     "iopub.status.busy": "2026-02-07T15:31:20.665267Z",
     "iopub.status.idle": "2026-02-07T15:31:28.103500Z",
     "shell.execute_reply": "2026-02-07T15:31:28.102799Z"
    },
    "papermill": {
     "duration": 7.444881,
     "end_time": "2026-02-07T15:31:28.105208",
     "exception": false,
     "start_time": "2026-02-07T15:31:20.660327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Target encoded: ['Absence', 'Presence'] -> [0, 1]\n",
      "Features after alignment: 30\n",
      "Numerical: 30, Categorical: 0\n",
      "‚úÖ Using QuantileTransformer (output=normal)\n",
      "\n",
      "Final shapes:\n",
      "X: (630000, 30)\n",
      "y: (630000,)\n",
      "X_test: (270000, 30)\n",
      "\n",
      "y unique values: [1 0]  (should be [0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Apply Preprocessing\n",
    "X, y, X_test = preprocess_data(train_fe, test_fe, TARGET, ID_COL, n_folds=10, use_quantile=True)\n",
    "\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"\\ny unique values: {y.unique()}  (should be [0, 1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5956e",
   "metadata": {
    "papermill": {
     "duration": 0.004433,
     "end_time": "2026-02-07T15:31:28.114564",
     "exception": false,
     "start_time": "2026-02-07T15:31:28.110131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 5. Model Training with Seed Averaging (7 Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29cc18d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:28.124826Z",
     "iopub.status.busy": "2026-02-07T15:31:28.124567Z",
     "iopub.status.idle": "2026-02-07T15:31:28.131450Z",
     "shell.execute_reply": "2026-02-07T15:31:28.130939Z"
    },
    "papermill": {
     "duration": 0.013898,
     "end_time": "2026-02-07T15:31:28.132857",
     "exception": false,
     "start_time": "2026-02-07T15:31:28.118959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model parameters defined with stronger regularization\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "N_FOLDS = 10\n",
    "\n",
    "def get_model_params(seed):\n",
    "    \"\"\"Get model parameters with specific seed - STRONGER REGULARIZATION\"\"\"\n",
    "    return {\n",
    "        'lgb': {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': seed,\n",
    "            'learning_rate': 0.02,  # Lower LR\n",
    "            'n_estimators': 3000,   # More trees\n",
    "            'num_leaves': 31,       # Reduced from 50\n",
    "            'max_depth': 6,         # Reduced from 8\n",
    "            'feature_fraction': 0.7,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq': 5,\n",
    "            'min_child_samples': 30,  # Increased from 20\n",
    "            'reg_alpha': 0.5,         # Increased from 0.1\n",
    "            'reg_lambda': 0.5,        # Increased from 0.1\n",
    "        },\n",
    "        'xgb': {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'tree_method': 'hist',\n",
    "            'random_state': seed,\n",
    "            'learning_rate': 0.02,\n",
    "            'n_estimators': 3000,\n",
    "            'max_depth': 5,         # Reduced from 7\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'reg_alpha': 0.5,\n",
    "            'reg_lambda': 0.5,\n",
    "            'min_child_weight': 15,  # Increased from 10\n",
    "        },\n",
    "        'cat': {\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'random_state': seed,\n",
    "            'learning_rate': 0.02,\n",
    "            'iterations': 3000,\n",
    "            'depth': 5,             # Reduced from 7\n",
    "            'l2_leaf_reg': 5,       # Increased from 3\n",
    "            'verbose': False,\n",
    "        },\n",
    "        'hgb': {\n",
    "            'learning_rate': 0.02,\n",
    "            'max_iter': 3000,\n",
    "            'max_depth': 6,\n",
    "            'min_samples_leaf': 30,\n",
    "            'l2_regularization': 0.5,\n",
    "            'random_state': seed,\n",
    "        },\n",
    "        'et': {\n",
    "            'n_estimators': 800,\n",
    "            'max_depth': 12,        # Reduced from 15\n",
    "            'min_samples_split': 15,\n",
    "            'min_samples_leaf': 8,\n",
    "            'random_state': seed,\n",
    "            'n_jobs': -1,\n",
    "        },\n",
    "        'rf': {\n",
    "            'n_estimators': 800,\n",
    "            'max_depth': 12,\n",
    "            'min_samples_split': 15,\n",
    "            'min_samples_leaf': 8,\n",
    "            'random_state': seed,\n",
    "            'n_jobs': -1,\n",
    "        },\n",
    "        'gnb': {},  # GaussianNB has no hyperparameters\n",
    "    }\n",
    "\n",
    "print(f\"‚úÖ Model parameters defined with stronger regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2804b28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:28.142996Z",
     "iopub.status.busy": "2026-02-07T15:31:28.142757Z",
     "iopub.status.idle": "2026-02-07T15:31:28.155350Z",
     "shell.execute_reply": "2026-02-07T15:31:28.154506Z"
    },
    "papermill": {
     "duration": 0.01936,
     "end_time": "2026-02-07T15:31:28.156699",
     "exception": false,
     "start_time": "2026-02-07T15:31:28.137339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined!\n"
     ]
    }
   ],
   "source": [
    "def train_single_seed(seed):\n",
    "    \"\"\"Train all models with a single seed\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING WITH SEED {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    params = get_model_params(seed)\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    oof_lgb = np.zeros(len(X))\n",
    "    oof_xgb = np.zeros(len(X))\n",
    "    oof_cat = np.zeros(len(X))\n",
    "    oof_hgb = np.zeros(len(X))\n",
    "    oof_et = np.zeros(len(X))\n",
    "    oof_rf = np.zeros(len(X))\n",
    "    oof_gnb = np.zeros(len(X))\n",
    "    \n",
    "    test_lgb = np.zeros(len(X_test))\n",
    "    test_xgb = np.zeros(len(X_test))\n",
    "    test_cat = np.zeros(len(X_test))\n",
    "    test_hgb = np.zeros(len(X_test))\n",
    "    test_et = np.zeros(len(X_test))\n",
    "    test_rf = np.zeros(len(X_test))\n",
    "    test_gnb = np.zeros(len(X_test))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"  Fold {fold + 1}/{N_FOLDS}\", end=\" \")\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # LightGBM\n",
    "        model_lgb = LGBMClassifier(**params['lgb'])\n",
    "        model_lgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[])\n",
    "        oof_lgb[val_idx] = model_lgb.predict_proba(X_val)[:, 1]\n",
    "        test_lgb += model_lgb.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        # XGBoost\n",
    "        model_xgb = XGBClassifier(**params['xgb'])\n",
    "        model_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        oof_xgb[val_idx] = model_xgb.predict_proba(X_val)[:, 1]\n",
    "        test_xgb += model_xgb.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        # CatBoost\n",
    "        model_cat = CatBoostClassifier(**params['cat'])\n",
    "        model_cat.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=200)\n",
    "        oof_cat[val_idx] = model_cat.predict_proba(X_val)[:, 1]\n",
    "        test_cat += model_cat.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        # HistGradientBoosting\n",
    "        model_hgb = HistGradientBoostingClassifier(**params['hgb'])\n",
    "        model_hgb.fit(X_train, y_train)\n",
    "        oof_hgb[val_idx] = model_hgb.predict_proba(X_val)[:, 1]\n",
    "        test_hgb += model_hgb.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        # ExtraTrees\n",
    "        model_et = ExtraTreesClassifier(**params['et'])\n",
    "        model_et.fit(X_train, y_train)\n",
    "        oof_et[val_idx] = model_et.predict_proba(X_val)[:, 1]\n",
    "        test_et += model_et.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        # RandomForest\n",
    "        model_rf = RandomForestClassifier(**params['rf'])\n",
    "        model_rf.fit(X_train, y_train)\n",
    "        oof_rf[val_idx] = model_rf.predict_proba(X_val)[:, 1]\n",
    "        test_rf += model_rf.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        # GaussianNB\n",
    "        model_gnb = GaussianNB()\n",
    "        model_gnb.fit(X_train, y_train)\n",
    "        oof_gnb[val_idx] = model_gnb.predict_proba(X_val)[:, 1]\n",
    "        test_gnb += model_gnb.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "        \n",
    "        print(f\"‚úì\")\n",
    "    \n",
    "    # Calculate scores\n",
    "    scores = {\n",
    "        'LightGBM': roc_auc_score(y, oof_lgb),\n",
    "        'XGBoost': roc_auc_score(y, oof_xgb),\n",
    "        'CatBoost': roc_auc_score(y, oof_cat),\n",
    "        'HistGradientBoosting': roc_auc_score(y, oof_hgb),\n",
    "        'ExtraTrees': roc_auc_score(y, oof_et),\n",
    "        'RandomForest': roc_auc_score(y, oof_rf),\n",
    "        'GaussianNB': roc_auc_score(y, oof_gnb),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nSeed {seed} OOF Scores:\")\n",
    "    for name, score in scores.items():\n",
    "        print(f\"  {name}: {score:.5f}\")\n",
    "    \n",
    "    return {\n",
    "        'oof': [oof_lgb, oof_xgb, oof_cat, oof_hgb, oof_et, oof_rf, oof_gnb],\n",
    "        'test': [test_lgb, test_xgb, test_cat, test_hgb, test_et, test_rf, test_gnb],\n",
    "        'scores': scores\n",
    "    }\n",
    "\n",
    "print(\"Training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345a30a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T15:31:28.166613Z",
     "iopub.status.busy": "2026-02-07T15:31:28.166395Z",
     "iopub.status.idle": "2026-02-08T00:08:50.872390Z",
     "shell.execute_reply": "2026-02-08T00:08:50.871562Z"
    },
    "papermill": {
     "duration": 31042.71269,
     "end_time": "2026-02-08T00:08:50.873932",
     "exception": false,
     "start_time": "2026-02-07T15:31:28.161242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING WITH 3 SEEDS FOR AVERAGING\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TRAINING WITH SEED 42\n",
      "============================================================\n",
      "  Fold 1/10 ‚úì\n",
      "  Fold 2/10 ‚úì\n",
      "  Fold 3/10 ‚úì\n",
      "  Fold 4/10 ‚úì\n",
      "  Fold 5/10 ‚úì\n",
      "  Fold 6/10 ‚úì\n",
      "  Fold 7/10 ‚úì\n",
      "  Fold 8/10 ‚úì\n",
      "  Fold 9/10 ‚úì\n",
      "  Fold 10/10 ‚úì\n",
      "\n",
      "Seed 42 OOF Scores:\n",
      "  LightGBM: 0.95516\n",
      "  XGBoost: 0.95526\n",
      "  CatBoost: 0.95545\n",
      "  HistGradientBoosting: 0.95514\n",
      "  ExtraTrees: 0.94728\n",
      "  RandomForest: 0.95243\n",
      "  GaussianNB: 0.91911\n",
      "\n",
      "============================================================\n",
      "TRAINING WITH SEED 123\n",
      "============================================================\n",
      "  Fold 1/10 ‚úì\n",
      "  Fold 2/10 ‚úì\n",
      "  Fold 3/10 ‚úì\n",
      "  Fold 4/10 ‚úì\n",
      "  Fold 5/10 ‚úì\n",
      "  Fold 6/10 ‚úì\n",
      "  Fold 7/10 ‚úì\n",
      "  Fold 8/10 ‚úì\n",
      "  Fold 9/10 ‚úì\n",
      "  Fold 10/10 ‚úì\n",
      "\n",
      "Seed 123 OOF Scores:\n",
      "  LightGBM: 0.95514\n",
      "  XGBoost: 0.95527\n",
      "  CatBoost: 0.95545\n",
      "  HistGradientBoosting: 0.95514\n",
      "  ExtraTrees: 0.94724\n",
      "  RandomForest: 0.95243\n",
      "  GaussianNB: 0.91911\n",
      "\n",
      "============================================================\n",
      "TRAINING WITH SEED 456\n",
      "============================================================\n",
      "  Fold 1/10 ‚úì\n",
      "  Fold 2/10 ‚úì\n",
      "  Fold 3/10 ‚úì\n",
      "  Fold 4/10 ‚úì\n",
      "  Fold 5/10 ‚úì\n",
      "  Fold 6/10 ‚úì\n",
      "  Fold 7/10 ‚úì\n",
      "  Fold 8/10 ‚úì\n",
      "  Fold 9/10 ‚úì\n",
      "  Fold 10/10 ‚úì\n",
      "\n",
      "Seed 456 OOF Scores:\n",
      "  LightGBM: 0.95518\n",
      "  XGBoost: 0.95529\n",
      "  CatBoost: 0.95545\n",
      "  HistGradientBoosting: 0.95515\n",
      "  ExtraTrees: 0.94736\n",
      "  RandomForest: 0.95243\n",
      "  GaussianNB: 0.91911\n",
      "\n",
      "‚úÖ All seeds trained!\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN WITH ALL SEEDS =====\n",
    "print(\"=\"*60)\n",
    "print(f\"TRAINING WITH {len(SEEDS)} SEEDS FOR AVERAGING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_results = []\n",
    "for seed in SEEDS:\n",
    "    result = train_single_seed(seed)\n",
    "    all_results.append(result)\n",
    "\n",
    "print(\"\\n‚úÖ All seeds trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf10b6b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:08:50.887275Z",
     "iopub.status.busy": "2026-02-08T00:08:50.886717Z",
     "iopub.status.idle": "2026-02-08T00:08:51.880293Z",
     "shell.execute_reply": "2026-02-08T00:08:51.879430Z"
    },
    "papermill": {
     "duration": 1.002151,
     "end_time": "2026-02-08T00:08:51.882070",
     "exception": false,
     "start_time": "2026-02-08T00:08:50.879919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SEED-AVERAGED OOF SCORES (More Robust!)\n",
      "============================================================\n",
      "LightGBM                 : 0.95525\n",
      "XGBoost                  : 0.95533\n",
      "CatBoost                 : 0.95547\n",
      "HistGradientBoosting     : 0.95521\n",
      "ExtraTrees               : 0.94731\n",
      "RandomForest             : 0.95246\n",
      "GaussianNB               : 0.91911\n"
     ]
    }
   ],
   "source": [
    "# ===== AVERAGE ACROSS SEEDS =====\n",
    "model_names = ['LightGBM', 'XGBoost', 'CatBoost', 'HistGradientBoosting', 'ExtraTrees', 'RandomForest', 'GaussianNB']\n",
    "n_models = len(model_names)\n",
    "\n",
    "# Average OOF and test predictions across all seeds\n",
    "oof_averaged = [np.mean([res['oof'][i] for res in all_results], axis=0) for i in range(n_models)]\n",
    "test_averaged = [np.mean([res['test'][i] for res in all_results], axis=0) for i in range(n_models)]\n",
    "\n",
    "# Calculate seed-averaged scores\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SEED-AVERAGED OOF SCORES (More Robust!)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "averaged_scores = {}\n",
    "for i, name in enumerate(model_names):\n",
    "    score = roc_auc_score(y, oof_averaged[i])\n",
    "    averaged_scores[name] = score\n",
    "    print(f\"{name:25s}: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784cdf64",
   "metadata": {
    "papermill": {
     "duration": 0.005981,
     "end_time": "2026-02-08T00:08:51.894360",
     "exception": false,
     "start_time": "2026-02-08T00:08:51.888379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 6. Advanced Ensemble Techniques (Blend-of-Blends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c68b42a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:08:51.907492Z",
     "iopub.status.busy": "2026-02-08T00:08:51.907028Z",
     "iopub.status.idle": "2026-02-08T00:08:52.402252Z",
     "shell.execute_reply": "2026-02-08T00:08:52.401321Z"
    },
    "papermill": {
     "duration": 0.503775,
     "end_time": "2026-02-08T00:08:52.403907",
     "exception": false,
     "start_time": "2026-02-08T00:08:51.900132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Rank Average OOF Score: 0.95395\n"
     ]
    }
   ],
   "source": [
    "# ===== 6.1 RANK AVERAGING =====\n",
    "def rank_average(predictions_list):\n",
    "    \"\"\"Convert predictions to ranks and average them\"\"\"\n",
    "    ranks = np.zeros_like(predictions_list[0])\n",
    "    for preds in predictions_list:\n",
    "        ranks += rankdata(preds)\n",
    "    return ranks / len(predictions_list)\n",
    "\n",
    "oof_rank = rank_average(oof_averaged)\n",
    "test_rank = rank_average(test_averaged)\n",
    "\n",
    "rank_score = roc_auc_score(y, oof_rank)\n",
    "print(f\"üéØ Rank Average OOF Score: {rank_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24bbf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:08:52.417718Z",
     "iopub.status.busy": "2026-02-08T00:08:52.417439Z",
     "iopub.status.idle": "2026-02-08T00:09:03.735279Z",
     "shell.execute_reply": "2026-02-08T00:09:03.734421Z"
    },
    "papermill": {
     "duration": 11.326719,
     "end_time": "2026-02-08T00:09:03.736977",
     "exception": false,
     "start_time": "2026-02-08T00:08:52.410258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized Ensemble Weights ===\n",
      "  LightGBM: 0.2608\n",
      "  XGBoost: 0.2313\n",
      "  CatBoost: 0.2599\n",
      "  HistGradientBoosting: 0.2039\n",
      "  ExtraTrees: 0.0000\n",
      "  RandomForest: 0.0442\n",
      "  GaussianNB: 0.0000\n",
      "\n",
      "üéØ Weighted Ensemble OOF Score: 0.95542\n"
     ]
    }
   ],
   "source": [
    "# ===== 6.2 OPTIMIZED WEIGHTED AVERAGE =====\n",
    "def optimize_weights(oofs, target):\n",
    "    \"\"\"Find optimal weights using scipy minimize\"\"\"\n",
    "    def objective(weights):\n",
    "        final_pred = np.sum([w * oof for w, oof in zip(weights, oofs)], axis=0)\n",
    "        return -roc_auc_score(target, final_pred)\n",
    "    \n",
    "    n_models = len(oofs)\n",
    "    initial_weights = [1/n_models] * n_models\n",
    "    \n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    \n",
    "    result = minimize(objective, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "optimal_weights = optimize_weights(oof_averaged, y)\n",
    "\n",
    "print(\"=== Optimized Ensemble Weights ===\")\n",
    "for name, weight in zip(model_names, optimal_weights):\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "oof_weighted = np.sum([w * oof for w, oof in zip(optimal_weights, oof_averaged)], axis=0)\n",
    "test_weighted = np.sum([w * oof for w, oof in zip(optimal_weights, test_averaged)], axis=0)\n",
    "\n",
    "weighted_score = roc_auc_score(y, oof_weighted)\n",
    "print(f\"\\nüéØ Weighted Ensemble OOF Score: {weighted_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a961b375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:03.751554Z",
     "iopub.status.busy": "2026-02-08T00:09:03.750968Z",
     "iopub.status.idle": "2026-02-08T00:09:06.430300Z",
     "shell.execute_reply": "2026-02-08T00:09:06.429534Z"
    },
    "papermill": {
     "duration": 2.68853,
     "end_time": "2026-02-08T00:09:06.432021",
     "exception": false,
     "start_time": "2026-02-08T00:09:03.743491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Stacking OOF Score: 0.95481\n"
     ]
    }
   ],
   "source": [
    "# ===== 6.3 STACKING META-LEARNER =====\n",
    "stack_train = np.column_stack(oof_averaged)\n",
    "stack_test = np.column_stack(test_averaged)\n",
    "\n",
    "meta_model = LogisticRegression(random_state=BASE_SEED, max_iter=1000, C=0.3)\n",
    "meta_model.fit(stack_train, y)\n",
    "\n",
    "oof_stack = meta_model.predict_proba(stack_train)[:, 1]\n",
    "test_stack = meta_model.predict_proba(stack_test)[:, 1]\n",
    "\n",
    "stack_score = roc_auc_score(y, oof_stack)\n",
    "print(f\"üéØ Stacking OOF Score: {stack_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c667f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:06.445990Z",
     "iopub.status.busy": "2026-02-08T00:09:06.445748Z",
     "iopub.status.idle": "2026-02-08T00:09:06.622684Z",
     "shell.execute_reply": "2026-02-08T00:09:06.621876Z"
    },
    "papermill": {
     "duration": 0.185536,
     "end_time": "2026-02-08T00:09:06.624183",
     "exception": false,
     "start_time": "2026-02-08T00:09:06.438647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Geometric Mean OOF Score: 0.95182\n"
     ]
    }
   ],
   "source": [
    "# ===== 6.4 GEOMETRIC MEAN =====\n",
    "def geometric_mean(predictions_list):\n",
    "    \"\"\"Geometric mean of predictions\"\"\"\n",
    "    clipped = [np.clip(p, 1e-8, 1-1e-8) for p in predictions_list]\n",
    "    return np.exp(np.mean(np.log(clipped), axis=0))\n",
    "\n",
    "oof_geom = geometric_mean(oof_averaged)\n",
    "test_geom = geometric_mean(test_averaged)\n",
    "\n",
    "geom_score = roc_auc_score(y, oof_geom)\n",
    "print(f\"üéØ Geometric Mean OOF Score: {geom_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db438b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:06.638060Z",
     "iopub.status.busy": "2026-02-08T00:09:06.637821Z",
     "iopub.status.idle": "2026-02-08T00:09:06.783160Z",
     "shell.execute_reply": "2026-02-08T00:09:06.782386Z"
    },
    "papermill": {
     "duration": 0.154128,
     "end_time": "2026-02-08T00:09:06.784737",
     "exception": false,
     "start_time": "2026-02-08T00:09:06.630609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Blend-of-Blends OOF Score: 0.95475\n"
     ]
    }
   ],
   "source": [
    "# ===== 6.5 BLEND OF BLENDS (Ultimate Ensemble) =====\n",
    "# Combine all ensemble methods\n",
    "ensemble_oofs = [oof_rank, oof_weighted, oof_stack, oof_geom]\n",
    "ensemble_tests = [test_rank, test_weighted, test_stack, test_geom]\n",
    "\n",
    "# Normalize rank predictions to 0-1\n",
    "oof_rank_norm = (oof_rank - oof_rank.min()) / (oof_rank.max() - oof_rank.min())\n",
    "test_rank_norm = (test_rank - test_rank.min()) / (test_rank.max() - test_rank.min())\n",
    "\n",
    "# Blend of blends with equal weights\n",
    "oof_blend = (oof_rank_norm + oof_weighted + oof_stack + oof_geom) / 4\n",
    "test_blend = (test_rank_norm + test_weighted + test_stack + test_geom) / 4\n",
    "\n",
    "blend_score = roc_auc_score(y, oof_blend)\n",
    "print(f\"üéØ Blend-of-Blends OOF Score: {blend_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "649edbbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:06.799381Z",
     "iopub.status.busy": "2026-02-08T00:09:06.799155Z",
     "iopub.status.idle": "2026-02-08T00:09:09.937886Z",
     "shell.execute_reply": "2026-02-08T00:09:09.937097Z"
    },
    "papermill": {
     "duration": 3.147304,
     "end_time": "2026-02-08T00:09:09.939440",
     "exception": false,
     "start_time": "2026-02-08T00:09:06.792136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Blend-of-Blends Optimized Weights ===\n",
      "  Rank Avg: 0.2473\n",
      "  Weighted: 0.2521\n",
      "  Stacking: 0.2527\n",
      "  Geometric: 0.2479\n",
      "\n",
      "üéØ Optimized Blend-of-Blends OOF Score: 0.95476\n"
     ]
    }
   ],
   "source": [
    "# ===== 6.6 OPTIMIZED BLEND OF BLENDS =====\n",
    "blend_preds = [oof_rank_norm, oof_weighted, oof_stack, oof_geom]\n",
    "blend_tests_all = [test_rank_norm, test_weighted, test_stack, test_geom]\n",
    "\n",
    "optimal_blend_weights = optimize_weights(blend_preds, y)\n",
    "\n",
    "print(\"=== Blend-of-Blends Optimized Weights ===\")\n",
    "blend_names = ['Rank Avg', 'Weighted', 'Stacking', 'Geometric']\n",
    "for name, weight in zip(blend_names, optimal_blend_weights):\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "oof_optimal_blend = np.sum([w * p for w, p in zip(optimal_blend_weights, blend_preds)], axis=0)\n",
    "test_optimal_blend = np.sum([w * p for w, p in zip(optimal_blend_weights, blend_tests_all)], axis=0)\n",
    "\n",
    "optimal_blend_score = roc_auc_score(y, oof_optimal_blend)\n",
    "print(f\"\\nüéØ Optimized Blend-of-Blends OOF Score: {optimal_blend_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f3369de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:09.954219Z",
     "iopub.status.busy": "2026-02-08T00:09:09.953652Z",
     "iopub.status.idle": "2026-02-08T00:09:09.959431Z",
     "shell.execute_reply": "2026-02-08T00:09:09.958674Z"
    },
    "papermill": {
     "duration": 0.014392,
     "end_time": "2026-02-08T00:09:09.960767",
     "exception": false,
     "start_time": "2026-02-08T00:09:09.946375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL COMPARISON - ALL METHODS\n",
      "============================================================\n",
      "CatBoost                 : 0.95547\n",
      "Weighted Ensemble        : 0.95542\n",
      "XGBoost                  : 0.95533\n",
      "LightGBM                 : 0.95525\n",
      "HistGradientBoosting     : 0.95521\n",
      "Stacking                 : 0.95481\n",
      "Optimal Blend            : 0.95476\n",
      "Blend-of-Blends          : 0.95475\n",
      "Rank Average             : 0.95395\n",
      "RandomForest             : 0.95246\n",
      "Geometric Mean           : 0.95182\n",
      "ExtraTrees               : 0.94731\n",
      "GaussianNB               : 0.91911\n",
      "\n",
      "üèÜ BEST METHOD: CatBoost with 0.95547\n"
     ]
    }
   ],
   "source": [
    "# ===== FINAL COMPARISON =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON - ALL METHODS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_scores = {\n",
    "    **averaged_scores,\n",
    "    'Rank Average': rank_score,\n",
    "    'Weighted Ensemble': weighted_score,\n",
    "    'Stacking': stack_score,\n",
    "    'Geometric Mean': geom_score,\n",
    "    'Blend-of-Blends': blend_score,\n",
    "    'Optimal Blend': optimal_blend_score,\n",
    "}\n",
    "\n",
    "for method, score in sorted(all_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{method:25s}: {score:.5f}\")\n",
    "\n",
    "best_method = max(all_scores, key=all_scores.get)\n",
    "print(f\"\\nüèÜ BEST METHOD: {best_method} with {all_scores[best_method]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e7ffa",
   "metadata": {
    "papermill": {
     "duration": 0.006209,
     "end_time": "2026-02-08T00:09:09.973153",
     "exception": false,
     "start_time": "2026-02-08T00:09:09.966944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 7. Pseudo-Labeling (Optional - Risky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d9c313c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:09.986552Z",
     "iopub.status.busy": "2026-02-08T00:09:09.986328Z",
     "iopub.status.idle": "2026-02-08T00:09:09.992150Z",
     "shell.execute_reply": "2026-02-08T00:09:09.991447Z"
    },
    "papermill": {
     "duration": 0.014166,
     "end_time": "2026-02-08T00:09:09.993458",
     "exception": false,
     "start_time": "2026-02-08T00:09:09.979292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è© Pseudo-labeling disabled. Set USE_PSEUDO_LABELING = True to enable.\n"
     ]
    }
   ],
   "source": [
    "# ===== SET THIS TO TRUE TO ENABLE PSEUDO-LABELING =====\n",
    "USE_PSEUDO_LABELING = False  # Set to True for aggressive approach\n",
    "CONFIDENCE_THRESHOLD = 0.95\n",
    "\n",
    "if USE_PSEUDO_LABELING:\n",
    "    print(\"=== Pseudo-Labeling ===\")\n",
    "    # Use best method predictions\n",
    "    if best_method == 'Optimal Blend':\n",
    "        pseudo_preds = test_optimal_blend\n",
    "    elif best_method == 'Blend-of-Blends':\n",
    "        pseudo_preds = test_blend\n",
    "    else:\n",
    "        pseudo_preds = test_weighted\n",
    "    \n",
    "    high_conf_mask = (pseudo_preds > CONFIDENCE_THRESHOLD) | (pseudo_preds < (1 - CONFIDENCE_THRESHOLD))\n",
    "    n_pseudo = high_conf_mask.sum()\n",
    "    \n",
    "    print(f\"High confidence samples: {n_pseudo} ({100*n_pseudo/len(pseudo_preds):.1f}%)\")\n",
    "    \n",
    "    if n_pseudo > 100:\n",
    "        pseudo_X = X_test[high_conf_mask]\n",
    "        pseudo_y = (pseudo_preds[high_conf_mask] > 0.5).astype(int)\n",
    "        \n",
    "        X_augmented = pd.concat([X, pseudo_X], ignore_index=True)\n",
    "        y_augmented = pd.concat([y, pd.Series(pseudo_y)], ignore_index=True)\n",
    "        \n",
    "        print(f\"Augmented training set: {len(X_augmented)} samples\")\n",
    "        # TODO: Retrain models with augmented data\n",
    "    else:\n",
    "        print(\"Not enough high-confidence samples for pseudo-labeling\")\n",
    "else:\n",
    "    print(\"‚è© Pseudo-labeling disabled. Set USE_PSEUDO_LABELING = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46b6cc",
   "metadata": {
    "papermill": {
     "duration": 0.006307,
     "end_time": "2026-02-08T00:09:10.006067",
     "exception": false,
     "start_time": "2026-02-08T00:09:09.999760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 8. Optuna Hyperparameter Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f80e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:10.019894Z",
     "iopub.status.busy": "2026-02-08T00:09:10.019426Z",
     "iopub.status.idle": "2026-02-08T00:09:10.027649Z",
     "shell.execute_reply": "2026-02-08T00:09:10.026929Z"
    },
    "papermill": {
     "duration": 0.016751,
     "end_time": "2026-02-08T00:09:10.029028",
     "exception": false,
     "start_time": "2026-02-08T00:09:10.012277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è© Optuna skipped. Set RUN_OPTUNA = True to enable.\n"
     ]
    }
   ],
   "source": [
    "RUN_OPTUNA = False  # Set to True for tuning (takes ~60 min)\n",
    "N_TRIALS = 100\n",
    "\n",
    "def lgb_optuna_objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': BASE_SEED,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 80),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.9),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 0.9),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 5.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 5.0, log=True),\n",
    "        'n_estimators': 3000,\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    skf_tune = StratifiedKFold(n_splits=5, shuffle=True, random_state=BASE_SEED)\n",
    "    \n",
    "    for train_idx, val_idx in skf_tune.split(X, y):\n",
    "        X_tr, X_vl = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_vl = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_vl, y_vl)], callbacks=[])\n",
    "        \n",
    "        pred = model.predict_proba(X_vl)[:, 1]\n",
    "        scores.append(roc_auc_score(y_vl, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    print(\"=== Running Optuna Hyperparameter Tuning ===\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lgb_optuna_objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Best Optuna Score: {study.best_trial.value:.5f}\")\n",
    "    print(f\"Best Parameters: {study.best_trial.params}\")\n",
    "else:\n",
    "    print(\"‚è© Optuna skipped. Set RUN_OPTUNA = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e1aa5",
   "metadata": {
    "papermill": {
     "duration": 0.006273,
     "end_time": "2026-02-08T00:09:10.042602",
     "exception": false,
     "start_time": "2026-02-08T00:09:10.036329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 9. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "193123c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:10.056111Z",
     "iopub.status.busy": "2026-02-08T00:09:10.055893Z",
     "iopub.status.idle": "2026-02-08T00:09:10.060864Z",
     "shell.execute_reply": "2026-02-08T00:09:10.060309Z"
    },
    "papermill": {
     "duration": 0.013275,
     "end_time": "2026-02-08T00:09:10.062141",
     "exception": false,
     "start_time": "2026-02-08T00:09:10.048866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using: CatBoost\n",
      "Prediction range: [0.0084, 0.9919]\n"
     ]
    }
   ],
   "source": [
    "# Select best predictions\n",
    "all_test_preds = {\n",
    "    'Rank Average': test_rank_norm,\n",
    "    'Weighted Ensemble': test_weighted,\n",
    "    'Stacking': test_stack,\n",
    "    'Geometric Mean': test_geom,\n",
    "    'Blend-of-Blends': test_blend,\n",
    "    'Optimal Blend': test_optimal_blend,\n",
    "}\n",
    "\n",
    "# Use the best method\n",
    "final_preds = all_test_preds.get(best_method, test_optimal_blend)\n",
    "\n",
    "# Clip to avoid extreme values\n",
    "final_preds = np.clip(final_preds, 0.001, 0.999)\n",
    "\n",
    "print(f\"‚úÖ Using: {best_method}\")\n",
    "print(f\"Prediction range: [{final_preds.min():.4f}, {final_preds.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "425a38b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:10.076423Z",
     "iopub.status.busy": "2026-02-08T00:09:10.076220Z",
     "iopub.status.idle": "2026-02-08T00:09:10.579147Z",
     "shell.execute_reply": "2026-02-08T00:09:10.578422Z"
    },
    "papermill": {
     "duration": 0.512104,
     "end_time": "2026-02-08T00:09:10.580526",
     "exception": false,
     "start_time": "2026-02-08T00:09:10.068422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ ULTRA SUBMISSION FILE GENERATED!\n",
      "============================================================\n",
      "\n",
      "File: submission_ultra.csv\n",
      "Shape: (270000, 2)\n",
      "\n",
      "Expected Score: 0.95547 (OOF)\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Heart Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630000</td>\n",
       "      <td>0.901901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630001</td>\n",
       "      <td>0.026209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630002</td>\n",
       "      <td>0.960942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630003</td>\n",
       "      <td>0.019671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630004</td>\n",
       "      <td>0.241521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>630005</td>\n",
       "      <td>0.956119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>630006</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>630007</td>\n",
       "      <td>0.639017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630008</td>\n",
       "      <td>0.974230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>630009</td>\n",
       "      <td>0.042433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Heart Disease\n",
       "0  630000       0.901901\n",
       "1  630001       0.026209\n",
       "2  630002       0.960942\n",
       "3  630003       0.019671\n",
       "4  630004       0.241521\n",
       "5  630005       0.956119\n",
       "6  630006       0.036145\n",
       "7  630007       0.639017\n",
       "8  630008       0.974230\n",
       "9  630009       0.042433"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test[ID_COL],\n",
    "    TARGET: final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_ultra.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ULTRA SUBMISSION FILE GENERATED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFile: submission_ultra.csv\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"\\nExpected Score: {all_scores[best_method]:.5f} (OOF)\")\n",
    "print(\"\\nPreview:\")\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9d05871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:09:10.595355Z",
     "iopub.status.busy": "2026-02-08T00:09:10.594906Z",
     "iopub.status.idle": "2026-02-08T00:09:10.599566Z",
     "shell.execute_reply": "2026-02-08T00:09:10.598896Z"
    },
    "papermill": {
     "duration": 0.013434,
     "end_time": "2026-02-08T00:09:10.600898",
     "exception": false,
     "start_time": "2026-02-08T00:09:10.587464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÜ ULTRA OPTIMIZATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Models Used: 7 (LGB, XGB, CatBoost, HistGBT, ExtraTrees, RandomForest, GaussianNB)\n",
      "Seeds Averaged: 3 seeds\n",
      "CV Strategy: 10-Fold Stratified\n",
      "Features: 30\n",
      "\n",
      "Best Ensemble Method: CatBoost\n",
      "Expected LB Score: ~0.95547\n",
      "\n",
      "‚úÖ Ready to submit!\n"
     ]
    }
   ],
   "source": [
    "# ===== SUMMARY =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ ULTRA OPTIMIZATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModels Used: 7 (LGB, XGB, CatBoost, HistGBT, ExtraTrees, RandomForest, GaussianNB)\")\n",
    "print(f\"Seeds Averaged: {len(SEEDS)} seeds\")\n",
    "print(f\"CV Strategy: {N_FOLDS}-Fold Stratified\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"\\nBest Ensemble Method: {best_method}\")\n",
    "print(f\"Expected LB Score: ~{all_scores[best_method]:.5f}\")\n",
    "print(\"\\n‚úÖ Ready to submit!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15408205,
     "sourceId": 125192,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31082.836272,
   "end_time": "2026-02-08T00:09:11.425052",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-07T15:31:08.588780",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
